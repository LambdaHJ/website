"use strict";(self.webpackChunkkoordinator_sh=self.webpackChunkkoordinator_sh||[]).push([[477],{10:function(e){e.exports=JSON.parse('{"blogPosts":[{"id":"release-v0.2.0","metadata":{"permalink":"/blog/release-v0.2.0","editUrl":"https://github.com/koordinator-sh/koordinator.sh/edit/main/blog/2022-04-19-release/index.md","source":"@site/blog/2022-04-19-release/index.md","title":"Koordinator v0.2.0 - Enhanced node-side scheduling capabilities","description":"We\u2019re pleased to announce the release of Koordinator v0.2.0.","date":"2022-04-19T00:00:00.000Z","formattedDate":"April 19, 2022","tags":[{"label":"koordinator","permalink":"/blog/tags/koordinator"},{"label":"colocation","permalink":"/blog/tags/colocation"},{"label":"kubernetes","permalink":"/blog/tags/kubernetes"},{"label":"scheduling","permalink":"/blog/tags/scheduling"},{"label":"orchestration","permalink":"/blog/tags/orchestration"},{"label":"release","permalink":"/blog/tags/release"}],"readingTime":3.49,"truncated":false,"authors":[{"name":"Joseph","title":"Koordinator maintainer","url":"https://github.com/eahydra","imageURL":"https://github.com/eahydra.png","key":"joseph"}],"frontMatter":{"slug":"release-v0.2.0","title":"Koordinator v0.2.0 - Enhanced node-side scheduling capabilities","authors":["joseph"],"tags":["koordinator","colocation","kubernetes","scheduling","orchestration","release"]},"nextItem":{"title":"Koordinator v0.1.0 - QoS based scheduling system","permalink":"/blog/release-v0.1.0"}},"content":"We\u2019re pleased to announce the release of Koordinator v0.2.0.\\n\\n## Overview\\n\\nKoordinator v0.1.0 implements basic co-location scheduling capabilities, and after the project was released, it has received attention and positive responses from the community.\\nFor some issues that everyone cares about, such as how to isolate resources for best-effort workloads, how to ensure the runtime stability of latency-sensitiv applications in co-location scenarios, etc., we have enhanced node-side scheduling capabilities in koordinator v0.2.0 to solve these problems.\\n\\n## Install or Upgrade to Koordinator v0.2.0\\n\\n### Install with helms\\n\\nKoordinator can be simply installed by helm v3.5+, which is a simple command-line tool and you can get it from [here](https://github.com/helm/helm/releases).\\n\\n```shell\\n# Firstly add koordinator charts repository if you haven\'t do this.\\n$ helm repo add koordinator-sh https://koordinator-sh.github.io/charts/\\n\\n# [Optional]\\n$ helm repo update\\n\\n# Install the latest version.\\n$ helm install koordinator koordinator-sh/koordinator --version 0.2.0\\n```\\n\\n### Upgrade with helm\\n\\n```shell\\n# Firstly add koordinator charts repository if you haven\'t do this.\\n$ helm repo add koordinator-sh https://koordinator-sh.github.io/charts/\\n\\n# [Optional]\\n$ helm repo update\\n\\n# Upgrade the latest version.\\n$ helm upgrade koordinator koordinator-sh/koordinator --version 0.2.0 [--force]\\n```\\n\\nFor more details, please refer to the [installation manual](/docs/installation).\\n\\n## Isolate resources for best-effort workloads\\n\\nIn Koodinator v0.2.0, we refined the ability to isolate resources for best-effort worklods. \\n\\n`koordlet` will set the cgroup parameters according to the resources described in the Pod Spec. Currently supports setting CPU Request/Limit, and Memory Limit.\\n\\nFor CPU resources, only the case of `request == limit` is supported, and the support for the scenario of `request <= limit` will be supported in the next version.\\n\\n## Active eviction mechanism based on memory safety thresholds\\n\\nWhen latency-sensitiv applications are serving, memory usage may increase due to bursty traffic. Similarly, there may be similar scenarios for best-effort workloads, for example, the current computing load exceeds the expected resource Request/Limit. \\n\\nThese scenarios will lead to an increase in the overall memory usage of the node, which will have an unpredictable impact on the runtime stability of the node side. For example, it can reduce the quality of service of latency-sensitiv applications or even become unavailable. Especially in a co-location environment, it is more challenging.\\n\\nWe implemented an active eviction mechanism based on memory safety thresholds in Koodinator. \\n\\n`koordlet` will regularly check the recent memory usage of node and Pods to check whether the safty threshold is exceeded. If it exceeds, it will evict some best-effort Pods to release memory. This mechanism can better ensure the stability of node and latency-sensitiv applications.\\n\\n`koordlet` currently only evicts best-effort Pods, sorted according to the Priority specified in the Pod Spec. The lower the priority, the higher the priority to be evicted, the same priority will be sorted according to the memory usage rate (RSS), the higher the memory usage, the higher the priority to be evicted. This eviction selection algorithm is not static. More dimensions will be considered in the future, and more refined implementations will be implemented for more scenarios to achieve more reasonable evictions.\\n\\nThe current memory utilization safety threshold default value is 70%. You can modify the `memoryEvictThresholdPercent` in ConfigMap `slo-controller-config` according to the actual situation, \\n\\n```yaml\\napiVersion: v1\\nkind: ConfigMap\\nmetadata:\\n  name: slo-controller-config\\n  namespace: koordinator-system\\ndata:\\n  colocation-config: |\\n    {\\n      \\"enable\\": true\\n    }\\n  resource-threshold-config: |\\n    {\\n      \\"clusterStrategy\\": {\\n        \\"enable\\": true,\\n        \\"memoryEvictThresholdPercent\\": 70\\n      }\\n    }\\n```\\n\\n## CPU Burst - Improve the performance of latency-sensitive applications\\n\\nCPU Burst is a service level objective (SLO)-aware resource scheduling feature. You can use CPU Burst to improve the performance of latency-sensitive applications. CPU scheduling for a container may be throttled by the kernel due to the CPU limit, which downgrades the performance of the application. Koordinator automatically detects CPU throttling events and automatically adjusts the CPU limit to a proper value. This greatly improves the performance of latency-sensitive applications. \\n\\nThe code of CPU Burst has been developed and is still under review and testing. It will be released in the next version. If you want to use this ability early, you are welcome to participate in Koordiantor and improve it together. For more details, please refer to the PR [#73](https://github.com/koordinator-sh/koordinator/pull/73).\\n\\n## More\\n\\nFor more details, please refer to the [Documentation](/docs). Hope it helps!"},{"id":"release-v0.1.0","metadata":{"permalink":"/blog/release-v0.1.0","editUrl":"https://github.com/koordinator-sh/koordinator.sh/edit/main/blog/2022-03-31-release/index.md","source":"@site/blog/2022-03-31-release/index.md","title":"Koordinator v0.1.0 - QoS based scheduling system","description":"We\u2019re pleased to announce the release of Koordinator v0.1.0.","date":"2022-03-31T00:00:00.000Z","formattedDate":"March 31, 2022","tags":[{"label":"koordinator","permalink":"/blog/tags/koordinator"},{"label":"colocation","permalink":"/blog/tags/colocation"},{"label":"kubernetes","permalink":"/blog/tags/kubernetes"},{"label":"scheduling","permalink":"/blog/tags/scheduling"},{"label":"orchestration","permalink":"/blog/tags/orchestration"},{"label":"release","permalink":"/blog/tags/release"}],"readingTime":4.21,"truncated":false,"authors":[{"name":"Joseph","title":"Koordinator maintainer","url":"https://github.com/eahydra","imageURL":"https://github.com/eahydra.png","key":"joseph"},{"name":"Fangsong Zeng","title":"Koordinator maintainer","url":"https://github.com/hormes","imageURL":"https://github.com/hormes.png","key":"hormes"}],"frontMatter":{"slug":"release-v0.1.0","title":"Koordinator v0.1.0 - QoS based scheduling system","authors":["joseph","hormes"],"tags":["koordinator","colocation","kubernetes","scheduling","orchestration","release"]},"prevItem":{"title":"Koordinator v0.2.0 - Enhanced node-side scheduling capabilities","permalink":"/blog/release-v0.2.0"}},"content":"We\u2019re pleased to announce the release of Koordinator v0.1.0.\\n\\n## Overview\\nKoordinator is a QoS based scheduling system for hybrid workloads orchestration on Kubernetes. It aims to improve the runtime efficiency and reliability of both latency sensitive workloads and batch jobs, simplify the complexity of resource-related configuration tuning, and increase pod deployment density to improve resource utilizations.\\n\\n## Key Features\\nKoordinator enhances the kubernetes user experiences in the workload management by providing the following:\\n\\n- Well-designed [priority](/docs/core-concepts/priority) and [QoS](/docs/core-concepts/qos) mechanism to co-locate different types of workloads in a cluster and run different types of pods on a single node.\\nAllowing for resource overcommitments to achieve high resource utilizations but still satisfying the QoS guarantees by leveraging an application profiling mechanism.\\n- Fine-grained resource orchestration and isolation mechanism to improve the efficiency of latency-sensitive workloads and batch jobs.\\n- Flexible job scheduling mechanism to support workloads in specific areas, e.g., big data, AI, audio and video.\\n- A set of tools for monitoring, troubleshooting and operations.\\n\\n## Node Metrics \\n\\nKoordinator defines the `NodeMetrics` CRD, which is used to record the resource utilization of a single node and all Pods on the node. koordlet will regularly report and update `NodeMetrics`. You can view `NodeMetrics` with the following commands.\\n\\n```shell\\n$ kubectl get nodemetrics node-1 -o yaml\\napiVersion: slo.koordinator.sh/v1alpha1\\nkind: NodeMetric\\nmetadata:\\n  creationTimestamp: \\"2022-03-30T11:50:17Z\\"\\n  generation: 1\\n  name: node-1\\n  resourceVersion: \\"2687986\\"\\n  uid: 1567bb4b-87a7-4273-a8fd-f44125c62b80\\nspec: {}\\nstatus:\\n  nodeMetric:\\n    nodeUsage:\\n      resources:\\n        cpu: 138m\\n        memory: \\"1815637738\\"\\n  podsMetric:\\n  - name: storage-service-6c7c59f868-k72r5\\n    namespace: default\\n    podUsage:\\n      resources:\\n        cpu: \\"300m\\"\\n        memory: 17828Ki\\n```\\n\\n## Colocation Resources\\n\\nAfter the Koordinator is deployed in the K8s cluster, the Koordinator will calculate the CPU and Memory resources that have been allocated but not used according to the data of `NodeMetrics`. These resources are updated in Node in the form of extended resources. \\n\\n`koordinator.sh/batch-cpu` represents the CPU resources for Best Effort workloads, \\n`koordinator.sh/batch-memory` represents the Memory resources for Best Effort workloads. \\n\\nYou can view these resources with the following commands.\\n\\n```shell\\n$ kubectl describe node node-1\\nName:               node-1\\n....\\nCapacity:\\n  cpu:                          8\\n  ephemeral-storage:            103080204Ki\\n  koordinator.sh/batch-cpu:     4541\\n  koordinator.sh/batch-memory:  17236565027\\n  memory:                       32611012Ki\\n  pods:                         64\\nAllocatable:\\n  cpu:                          7800m\\n  ephemeral-storage:            94998715850\\n  koordinator.sh/batch-cpu:     4541\\n  koordinator.sh/batch-memory:  17236565027\\n  memory:                       28629700Ki\\n  pods:                         64\\n```\\n\\n\\n## Cluster-level Colocation Profile\\n\\nIn order to make it easier for everyone to use Koordinator to co-locate different workloads, we defined `ClusterColocationProfile` to help gray workloads use co-location resources. A `ClusterColocationProfile` is CRD like the one below. Please do edit each parameter to fit your own use cases.\\n\\n```yaml\\napiVersion: config.koordinator.sh/v1alpha1\\nkind: ClusterColocationProfile\\nmetadata:\\n  name: colocation-profile-example\\nspec:\\n  namespaceSelector:\\n    matchLabels:\\n      koordinator.sh/enable-colocation: \\"true\\"\\n  selector:\\n    matchLabels:\\n      sparkoperator.k8s.io/launched-by-spark-operator: \\"true\\"\\n  qosClass: BE\\n  priorityClassName: koord-batch\\n  koordinatorPriority: 1000\\n  schedulerName: koord-scheduler\\n  labels:\\n    koordinator.sh/mutated: \\"true\\"\\n  annotations: \\n    koordinator.sh/intercepted: \\"true\\"\\n  patch:\\n    spec:\\n      terminationGracePeriodSeconds: 30\\n```\\n\\nVarious Koordinator components ensure scheduling and runtime quality through labels `koordinator.sh/qosClass`, `koordinator.sh/priority` and kubernetes native priority.\\n\\nWith the webhook mutating mechanism provided by Kubernetes, koord-manager will modify Pod resource requirements to co-located resources, and inject the QoS and Priority defined by Koordinator into Pod.\\n\\nTaking the above Profile as an example, when the Spark Operator creates a new Pod in the namespace with the `koordinator.sh/enable-colocation=true` label, the Koordinator QoS label `koordinator.sh/qosClass` will be injected into the Pod. According to the Profile definition PriorityClassName, modify the Pod\'s PriorityClassName and the corresponding Priority value. Users can also set the Koordinator Priority according to their needs to achieve more fine-grained priority management, so the Koordinator Priority label `koordinator.sh/priority` is also injected into the Pod. Koordinator provides an enhanced scheduler koord-scheduler, so you need to modify the Pod\'s scheduler name koord-scheduler through Profile.\\n\\nIf you expect to integrate Koordinator into your own system, please learn more about the [core concepts](/docs/core-concepts/architecture).\\n\\n## CPU Suppress\\n\\nIn order to ensure the runtime quality of different workloads in co-located scenarios, Koordinator uses the CPU Suppress mechanism provided by koordlet on the node side to suppress workloads of the Best Effort type when the load increases. Or increase the resource quota for Best Effort type workloads when the load decreases.\\n\\nWhen installing through the helm chart, the ConfigMap `slo-controller-config` will be created in the koordinator-system namespace, and the CPU Suppress mechanism is enabled by default. If it needs to be closed, refer to the configuration below, and modify the configuration of the resource-threshold-config section to take effect.\\n\\n```yaml\\napiVersion: v1\\nkind: ConfigMap\\nmetadata:\\n  name: slo-controller-config\\n  namespace: {{ .Values.installation.namespace }}\\ndata:\\n  ...\\n  resource-threshold-config: |\\n    {\\n      \\"clusterStrategy\\": {\\n        \\"enable\\": false\\n      }\\n    }\\n```\\n\\n## Colocation Resources Balance\\nKoordinator currently adopts a strategy for node co-location resource scheduling, which prioritizes scheduling to machines with more resources remaining in co-location to avoid Best Effort workloads crowding together. More rich scheduling capabilities are on the way.\\n\\n## Tutorial - Colocation of Spark Jobs\\n\\nApache Spark is an analysis engine for large-scale data processing, which is widely used in Big Data, SQL Analysis and Machine Learning scenarios. \\nWe provide a tutorial to help you how to quickly use Koordinator to run Spark Jobs in colocation mode with other latency sensitive applications. For more details, please refer to the [tutorial](/docs/best-practices/colocation-of-spark-jobs).\\n\\n## Summary\\n\\nFore More details, please refer to the [Documentation](/docs). Hope it helps!"}]}')}}]);